#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒè¯•ColorHuntç½‘ç«™çš„HTMLç»“æ„
"""
import sys
import os
import requests
from bs4 import BeautifulSoup
import re

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def debug_colorhunt_page(tag='summer'):
    """è°ƒè¯•ColorHuntæ ‡ç­¾é¡µé¢çš„HTMLç»“æ„"""
    
    url = f"https://colorhunt.co/palettes/{tag}"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Referer': 'https://colorhunt.co/',
        'Cache-Control': 'no-cache'
    }
    
    print(f"ğŸ” è°ƒè¯•é¡µé¢: {url}")
    
    try:
        response = requests.get(url, headers=headers, timeout=15)
        print(f"ğŸ“Š å“åº”çŠ¶æ€ç : {response.status_code}")
        print(f"ğŸ“ å“åº”å†…å®¹é•¿åº¦: {len(response.text)} å­—ç¬¦")
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # 1. æŸ¥æ‰¾é¡µé¢æ ‡é¢˜
            title = soup.find('title')
            if title:
                print(f"ğŸ“„ é¡µé¢æ ‡é¢˜: {title.text.strip()}")
            
            # 2. æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„é…è‰²æ–¹æ¡ˆç›¸å…³å…ƒç´ 
            print("\nğŸ” æŸ¥æ‰¾é…è‰²æ–¹æ¡ˆç›¸å…³å…ƒç´ :")
            
            selectors_to_test = [
                '.palette',
                '.item',
                '.color-palette',
                '[data-id]',
                'a[href*="/palette/"]',
                '.palettes',
                '.palette-item',
                '.color-item',
                'div[class*="palette"]',
                'div[class*="color"]'
            ]
            
            for selector in selectors_to_test:
                elements = soup.select(selector)
                print(f"  {selector}: {len(elements)} ä¸ªå…ƒç´ ")
                
                if elements and len(elements) > 0:
                    # æ˜¾ç¤ºå‰2ä¸ªå…ƒç´ çš„è¯¦ç»†ä¿¡æ¯
                    for i, elem in enumerate(elements[:2]):
                        print(f"    å…ƒç´  {i+1}:")
                        print(f"      æ ‡ç­¾: {elem.name}")
                        print(f"      ç±»: {elem.get('class', [])}")
                        print(f"      ID: {elem.get('id', '')}")
                        print(f"      href: {elem.get('href', '')}")
                        print(f"      data-id: {elem.get('data-id', '')}")
                        print(f"      æ–‡æœ¬å†…å®¹: {elem.text.strip()[:100]}...")
            
            # 3. æŸ¥æ‰¾æ‰€æœ‰åŒ…å« /palette/ çš„é“¾æ¥
            print("\nğŸ”— æŸ¥æ‰¾é…è‰²æ–¹æ¡ˆé“¾æ¥:")
            palette_links = soup.find_all('a', href=re.compile(r'/palette/'))
            print(f"æ‰¾åˆ° {len(palette_links)} ä¸ªé…è‰²æ–¹æ¡ˆé“¾æ¥")
            
            for i, link in enumerate(palette_links[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
                href = link.get('href', '')
                print(f"  é“¾æ¥ {i+1}: {href}")
                print(f"    ç±»: {link.get('class', [])}")
                print(f"    æ–‡æœ¬: {link.text.strip()[:50]}...")
            
            # 4. æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½åŒ…å«é¢œè‰²ä»£ç çš„å…ƒç´ 
            print("\nğŸŒˆ æŸ¥æ‰¾é¢œè‰²ä»£ç :")
            color_pattern = re.compile(r'#[0-9a-fA-F]{6}')
            color_matches = color_pattern.findall(response.text)
            unique_colors = list(set(color_matches))
            print(f"æ‰¾åˆ° {len(unique_colors)} ä¸ªå”¯ä¸€é¢œè‰²ä»£ç :")
            for color in unique_colors[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"  {color}")
            
            # 5. æŸ¥æ‰¾JavaScriptä¸­çš„æ•°æ®
            print("\nğŸ“œ æŸ¥æ‰¾JavaScriptæ•°æ®:")
            scripts = soup.find_all('script')
            for i, script in enumerate(scripts):
                if script.string and ('palette' in script.string.lower() or 'color' in script.string.lower()):
                    content = script.string.strip()
                    if len(content) > 50:  # åªæ˜¾ç¤ºæœ‰æ„ä¹‰çš„è„šæœ¬
                        print(f"  è„šæœ¬ {i+1} (å‰200å­—ç¬¦): {content[:200]}...")
            
            # 6. æ£€æŸ¥æ˜¯å¦æœ‰"No results"ä¿¡æ¯
            no_results = soup.find(text=re.compile(r'No results|couldn\'t find'))
            if no_results:
                print(f"\nâš ï¸ å‘ç°'æ— ç»“æœ'ä¿¡æ¯: {no_results.strip()}")
            
            # 7. ä¿å­˜HTMLåˆ°æ–‡ä»¶ä»¥ä¾¿è¿›ä¸€æ­¥åˆ†æ
            with open(f'debug_{tag}_page.html', 'w', encoding='utf-8') as f:
                f.write(response.text)
            print(f"\nğŸ’¾ HTMLå†…å®¹å·²ä¿å­˜åˆ°: debug_{tag}_page.html")
            
        else:
            print(f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            
    except Exception as e:
        print(f"âŒ è°ƒè¯•æ—¶å‡ºé”™: {e}")

if __name__ == "__main__":
    # è°ƒè¯•ä¸åŒçš„æ ‡ç­¾é¡µé¢
    tags_to_debug = ['summer', 'retro', 'vintage']
    
    for tag in tags_to_debug:
        print(f"\n{'='*80}")
        debug_colorhunt_page(tag)
        print(f"{'='*80}") 