#!/usr/bin/env python
"""
æ­£ç¡®å¤„ç†å‹ç¼©å“åº”ï¼Œåˆ†æColorHunté…è‰²æ–¹æ¡ˆé¡µé¢çš„çœŸå®å†…å®¹
"""
import sys
import os
import json
import requests
from bs4 import BeautifulSoup
import re
import gzip
import time

def test_decompressed_response():
    """æµ‹è¯•æ­£ç¡®è§£å‹å“åº”å†…å®¹"""
    print("ğŸ” æµ‹è¯•æ­£ç¡®è§£å‹ColorHuntå“åº”å†…å®¹")
    print("=" * 60)
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1'
    }
    
    # æµ‹è¯•æˆªå›¾ä¸­çš„é…è‰²æ–¹æ¡ˆ
    target_code = '626f47a4b465f5ecd5f0bb78'
    url = f'https://colorhunt.co/palette/{target_code}'
    
    print(f"ğŸ¯ ç›®æ ‡URL: {url}")
    print("-" * 40)
    
    try:
        # ä½¿ç”¨requestsè‡ªåŠ¨å¤„ç†å‹ç¼©
        response = requests.get(url, headers=headers, timeout=15)
        
        print(f"çŠ¶æ€ç : {response.status_code}")
        print(f"å“åº”å¤´: {dict(response.headers)}")
        print(f"å“åº”é•¿åº¦: {len(response.text)}")
        print(f"ç¼–ç : {response.encoding}")
        
        if response.status_code == 200:
            # ä¿å­˜è§£å‹åçš„å†…å®¹
            with open('palette_decompressed.html', 'w', encoding='utf-8') as f:
                f.write(response.text)
            print("ğŸ“ å·²ä¿å­˜è§£å‹åçš„å†…å®¹: palette_decompressed.html")
            
            # åˆ†æé¡µé¢å†…å®¹
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æŸ¥æ‰¾æ ‡é¢˜
            title = soup.find('title')
            print(f"\né¡µé¢æ ‡é¢˜: {title.text if title else 'N/A'}")
            
            # æŸ¥æ‰¾æ‰€æœ‰é“¾æ¥
            links = soup.find_all('a')
            print(f"æ‰¾åˆ° {len(links)} ä¸ªé“¾æ¥")
            
            # æŸ¥æ‰¾æ ‡ç­¾ç›¸å…³çš„é“¾æ¥
            tag_links = []
            for link in links:
                href = link.get('href', '')
                text = link.text.strip()
                if '/palettes/' in href and text and len(text) < 20:
                    tag_links.append((text, href))
            
            print(f"æ ‡ç­¾é“¾æ¥: {tag_links}")
            
            # æŸ¥æ‰¾å¯èƒ½åŒ…å«æ ‡ç­¾çš„å…ƒç´ 
            tag_elements = soup.find_all(['div', 'span', 'a'], class_=re.compile(r'tag|label|category', re.I))
            print(f"æ‰¾åˆ° {len(tag_elements)} ä¸ªå¯èƒ½çš„æ ‡ç­¾å…ƒç´ ")
            
            for elem in tag_elements:
                print(f"  {elem.name}: {elem.get('class')} - {elem.text.strip()}")
            
            # æŸ¥æ‰¾åŒ…å«ç‰¹å®šå…³é”®è¯çš„å…ƒç´ 
            keywords = ['sage', 'green', 'beige', 'nature', 'earth', 'summer', 'food', 'vintage']
            found_keywords = []
            
            page_text = soup.get_text().lower()
            for keyword in keywords:
                if keyword in page_text:
                    found_keywords.append(keyword)
            
            print(f"åœ¨é¡µé¢ä¸­æ‰¾åˆ°çš„å…³é”®è¯: {found_keywords}")
            
            # æŸ¥æ‰¾scriptæ ‡ç­¾ä¸­çš„æ•°æ®
            scripts = soup.find_all('script')
            print(f"æ‰¾åˆ° {len(scripts)} ä¸ªscriptæ ‡ç­¾")
            
            for i, script in enumerate(scripts):
                if script.string and len(script.string) > 50:
                    script_content = script.string
                    if any(keyword in script_content.lower() for keyword in ['tag', 'palette', 'color']):
                        print(f"\nScript {i+1} åŒ…å«ç›¸å…³å†…å®¹:")
                        print(script_content[:300] + "..." if len(script_content) > 300 else script_content)
            
            # æŸ¥æ‰¾metaæ ‡ç­¾
            meta_tags = soup.find_all('meta')
            print(f"\næ‰¾åˆ° {len(meta_tags)} ä¸ªmetaæ ‡ç­¾")
            
            for meta in meta_tags:
                name = meta.get('name', meta.get('property', ''))
                content = meta.get('content', '')
                if name and content and any(keyword in content.lower() for keyword in keywords):
                    print(f"  {name}: {content}")
            
            # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«é¢œè‰²ä»£ç çš„å…ƒç´ 
            color_elements = soup.find_all(text=re.compile(r'#[0-9a-fA-F]{6}'))
            print(f"\næ‰¾åˆ° {len(color_elements)} ä¸ªåŒ…å«é¢œè‰²ä»£ç çš„å…ƒç´ ")
            
            # æŸ¥æ‰¾dataå±æ€§
            data_elements = soup.find_all(attrs={'data-tag': True})
            if data_elements:
                print(f"æ‰¾åˆ° {len(data_elements)} ä¸ªå¸¦æœ‰data-tagå±æ€§çš„å…ƒç´ ")
                for elem in data_elements:
                    print(f"  {elem.name}: data-tag='{elem.get('data-tag')}'")
            
        else:
            print(f"âŒ è¯·æ±‚å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

def test_javascript_rendering():
    """æµ‹è¯•æ˜¯å¦éœ€è¦JavaScriptæ¸²æŸ“"""
    print("\n" + "=" * 60)
    print("ğŸ” æµ‹è¯•JavaScriptæ¸²æŸ“éœ€æ±‚")
    print("=" * 60)
    
    # å°è¯•ä½¿ç”¨seleniumè·å–å®Œæ•´æ¸²æŸ“çš„é¡µé¢
    try:
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        from selenium.webdriver.common.by import By
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        
        print("âœ… Seleniumå¯ç”¨ï¼Œå°è¯•JavaScriptæ¸²æŸ“")
        
        # é…ç½®Chromeé€‰é¡¹
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        
        driver = webdriver.Chrome(options=chrome_options)
        
        target_code = '626f47a4b465f5ecd5f0bb78'
        url = f'https://colorhunt.co/palette/{target_code}'
        
        print(f"è®¿é—®: {url}")
        driver.get(url)
        
        # ç­‰å¾…é¡µé¢åŠ è½½
        time.sleep(3)
        
        # è·å–é¡µé¢æºç 
        page_source = driver.page_source
        
        # ä¿å­˜æ¸²æŸ“åçš„é¡µé¢
        with open('palette_rendered.html', 'w', encoding='utf-8') as f:
            f.write(page_source)
        print("ğŸ“ å·²ä¿å­˜æ¸²æŸ“åçš„é¡µé¢: palette_rendered.html")
        
        # åˆ†ææ¸²æŸ“åçš„é¡µé¢
        soup = BeautifulSoup(page_source, 'html.parser')
        
        # æŸ¥æ‰¾æ ‡ç­¾
        tag_links = soup.find_all('a', href=re.compile(r'/palettes/[a-zA-Z]+$'))
        tags = [link.text.strip() for link in tag_links if link.text.strip()]
        print(f"æ¸²æŸ“åæ‰¾åˆ°çš„æ ‡ç­¾: {list(set(tags))}")
        
        driver.quit()
        
    except ImportError:
        print("âš ï¸ Seleniumæœªå®‰è£…ï¼Œè·³è¿‡JavaScriptæ¸²æŸ“æµ‹è¯•")
        print("å¦‚éœ€å®‰è£…: pip install selenium")
    except Exception as e:
        print(f"âŒ Seleniumæµ‹è¯•å¼‚å¸¸: {e}")

def analyze_api_structure():
    """åˆ†æAPIç»“æ„ï¼Œçœ‹çœ‹æ˜¯å¦æœ‰å…¶ä»–ç«¯ç‚¹"""
    print("\n" + "=" * 60)
    print("ğŸ” åˆ†æAPIç»“æ„")
    print("=" * 60)
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        'Accept': 'application/json, text/html, */*',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
        'X-Requested-With': 'XMLHttpRequest',
        'Referer': 'https://colorhunt.co/'
    }
    
    # æµ‹è¯•ä¸åŒçš„APIå‚æ•°ç»„åˆ
    test_cases = [
        # å°è¯•è·å–ç‰¹å®šé…è‰²æ–¹æ¡ˆçš„è¯¦ç»†ä¿¡æ¯
        {'step': 0, 'sort': 'new', 'tags': '', 'timeframe': '', 'palette_id': '626f47a4b465f5ecd5f0bb78'},
        {'step': 0, 'sort': 'new', 'tags': '', 'timeframe': '', 'id': '626f47a4b465f5ecd5f0bb78'},
        {'step': 0, 'sort': 'new', 'tags': '', 'timeframe': '', 'code': '626f47a4b465f5ecd5f0bb78'},
        # å°è¯•è·å–æ ‡ç­¾ä¿¡æ¯
        {'action': 'get_tags', 'palette_id': '626f47a4b465f5ecd5f0bb78'},
        {'action': 'palette_details', 'id': '626f47a4b465f5ecd5f0bb78'},
    ]
    
    for i, post_data in enumerate(test_cases):
        print(f"\nğŸ“‹ æµ‹è¯•APIå‚æ•° {i+1}: {post_data}")
        
        try:
            response = requests.post(
                'https://colorhunt.co/php/feed.php', 
                headers=headers, 
                data=post_data,
                timeout=10
            )
            
            print(f"çŠ¶æ€ç : {response.status_code}")
            print(f"å“åº”é•¿åº¦: {len(response.text)}")
            
            if response.text.strip():
                print(f"å“åº”å†…å®¹: {response.text[:200]}...")
                
                # å°è¯•è§£æJSON
                try:
                    json_data = json.loads(response.text)
                    print(f"JSONæ•°æ®: {json_data}")
                except:
                    pass
            else:
                print("ç©ºå“åº”")
                
        except Exception as e:
            print(f"âŒ å¼‚å¸¸: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ColorHuntè§£å‹å“åº”å’Œæ ‡ç­¾åˆ†æ")
    print("=" * 60)
    
    try:
        test_decompressed_response()
        test_javascript_rendering()
        analyze_api_structure()
        
        print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
        print("ğŸ’¡ è¯´æ˜: é€šè¿‡æ­£ç¡®è§£å‹å“åº”å’ŒJavaScriptæ¸²æŸ“å°è¯•è·å–çœŸå®æ ‡ç­¾")
        print("ğŸ” æ£€æŸ¥ç”Ÿæˆçš„HTMLæ–‡ä»¶æŸ¥çœ‹è¯¦ç»†å†…å®¹ã€‚")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 