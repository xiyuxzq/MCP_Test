#!/usr/bin/env python
"""
ä¸“é—¨æµ‹è¯•ç‰¹å®šé…è‰²æ–¹æ¡ˆçš„æ ‡ç­¾è·å–
å°è¯•å¤šç§æ–¹æ³•è·å–çœŸå®çš„æ ‡ç­¾ä¿¡æ¯
"""
import sys
import os
import json
import requests
from bs4 import BeautifulSoup
import re
import time

def test_specific_palette_tags():
    """æµ‹è¯•ç‰¹å®šé…è‰²æ–¹æ¡ˆçš„æ ‡ç­¾è·å–"""
    print("ğŸ·ï¸ æµ‹è¯•ç‰¹å®šé…è‰²æ–¹æ¡ˆæ ‡ç­¾è·å–")
    print("=" * 60)
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Cache-Control': 'no-cache',
        'Pragma': 'no-cache'
    }
    
    # æµ‹è¯•æˆªå›¾ä¸­çš„é…è‰²æ–¹æ¡ˆ
    test_palette = {
        'code': '626f47a4b465f5ecd5f0bb78',
        'url': 'https://colorhunt.co/palette/626f47a4b465f5ecd5f0bb78',
        'expected_tags': ['Sage', 'Green', 'Beige', 'Nature', 'Earth', 'Summer', 'Food', 'Vintage']
    }
    
    print(f"ğŸ¯ ç›®æ ‡é…è‰²æ–¹æ¡ˆ: {test_palette['code']}")
    print(f"ğŸ”— URL: {test_palette['url']}")
    print(f"ğŸ“‹ æœŸæœ›æ ‡ç­¾: {test_palette['expected_tags']}")
    print("-" * 40)
    
    # æ–¹æ³•1: ç›´æ¥è®¿é—®é…è‰²æ–¹æ¡ˆé¡µé¢
    print("\nğŸ” æ–¹æ³•1: ç›´æ¥è®¿é—®é…è‰²æ–¹æ¡ˆé¡µé¢")
    try:
        response = requests.get(test_palette['url'], headers=headers, timeout=15)
        print(f"çŠ¶æ€ç : {response.status_code}")
        print(f"å“åº”é•¿åº¦: {len(response.text)}")
        
        if response.status_code == 200:
            # ä¿å­˜å®Œæ•´å“åº”ç”¨äºåˆ†æ
            with open('palette_response.html', 'w', encoding='utf-8') as f:
                f.write(response.text)
            print("ğŸ“ å·²ä¿å­˜å“åº”: palette_response.html")
            
            # åˆ†æé¡µé¢å†…å®¹
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æŸ¥æ‰¾æ ‡é¢˜
            title = soup.find('title')
            print(f"é¡µé¢æ ‡é¢˜: {title.text if title else 'N/A'}")
            
            # æŸ¥æ‰¾æ‰€æœ‰é“¾æ¥
            links = soup.find_all('a')
            print(f"æ‰¾åˆ° {len(links)} ä¸ªé“¾æ¥")
            
            # æŸ¥æ‰¾å¯èƒ½çš„æ ‡ç­¾é“¾æ¥
            tag_links = []
            for link in links:
                href = link.get('href', '')
                text = link.text.strip()
                if '/palettes/' in href and text:
                    tag_links.append((text, href))
            
            print(f"å¯èƒ½çš„æ ‡ç­¾é“¾æ¥: {tag_links}")
            
            # æŸ¥æ‰¾é¡µé¢ä¸­çš„æ‰€æœ‰æ–‡æœ¬
            page_text = soup.get_text()
            print(f"é¡µé¢æ–‡æœ¬é•¿åº¦: {len(page_text)}")
            
            # åœ¨é¡µé¢æ–‡æœ¬ä¸­æŸ¥æ‰¾æœŸæœ›çš„æ ‡ç­¾
            found_tags = []
            for tag in test_palette['expected_tags']:
                if tag.lower() in page_text.lower():
                    found_tags.append(tag)
            
            print(f"åœ¨é¡µé¢æ–‡æœ¬ä¸­æ‰¾åˆ°çš„æœŸæœ›æ ‡ç­¾: {found_tags}")
            
        else:
            print(f"âŒ è¯·æ±‚å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ æ–¹æ³•1å¼‚å¸¸: {e}")
    
    # æ–¹æ³•2: å°è¯•è·å–é¡µé¢çš„JSONæ•°æ®
    print("\nğŸ” æ–¹æ³•2: æŸ¥æ‰¾é¡µé¢ä¸­çš„JSONæ•°æ®")
    try:
        response = requests.get(test_palette['url'], headers=headers, timeout=15)
        if response.status_code == 200:
            # æŸ¥æ‰¾scriptæ ‡ç­¾ä¸­çš„JSONæ•°æ®
            soup = BeautifulSoup(response.text, 'html.parser')
            scripts = soup.find_all('script')
            
            for i, script in enumerate(scripts):
                if script.string:
                    script_content = script.string
                    # æŸ¥æ‰¾å¯èƒ½åŒ…å«æ ‡ç­¾ä¿¡æ¯çš„JSON
                    if 'tag' in script_content.lower() or 'palette' in script_content.lower():
                        print(f"Script {i+1} åŒ…å«ç›¸å…³å†…å®¹:")
                        print(script_content[:500] + "..." if len(script_content) > 500 else script_content)
                        
                        # å°è¯•æå–JSON
                        json_matches = re.findall(r'\{[^{}]*\}', script_content)
                        for j, json_str in enumerate(json_matches):
                            try:
                                json_data = json.loads(json_str)
                                print(f"  JSON {j+1}: {json_data}")
                            except:
                                pass
    except Exception as e:
        print(f"âŒ æ–¹æ³•2å¼‚å¸¸: {e}")
    
    # æ–¹æ³•3: å°è¯•è®¿é—®å¯èƒ½çš„APIç«¯ç‚¹
    print("\nğŸ” æ–¹æ³•3: å°è¯•è®¿é—®å¯èƒ½çš„APIç«¯ç‚¹")
    api_endpoints = [
        f"https://colorhunt.co/api/palette/{test_palette['code']}",
        f"https://colorhunt.co/php/palette.php?id={test_palette['code']}",
        f"https://colorhunt.co/palette/{test_palette['code']}.json"
    ]
    
    for endpoint in api_endpoints:
        try:
            print(f"å°è¯•: {endpoint}")
            response = requests.get(endpoint, headers=headers, timeout=10)
            print(f"  çŠ¶æ€ç : {response.status_code}")
            if response.status_code == 200:
                print(f"  å“åº”: {response.text[:200]}...")
                try:
                    json_data = json.loads(response.text)
                    print(f"  JSONæ•°æ®: {json_data}")
                except:
                    pass
        except Exception as e:
            print(f"  å¼‚å¸¸: {e}")
    
    # æ–¹æ³•4: åˆ†æColorHuntä¸»é¡µï¼Œçœ‹çœ‹æ ‡ç­¾æ˜¯å¦‚ä½•ç»„ç»‡çš„
    print("\nğŸ” æ–¹æ³•4: åˆ†æColorHuntä¸»é¡µæ ‡ç­¾ç»“æ„")
    try:
        response = requests.get('https://colorhunt.co/', headers=headers, timeout=10)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æŸ¥æ‰¾æ ‡ç­¾ç›¸å…³çš„å…ƒç´ 
            tag_elements = soup.find_all(['a', 'div', 'span'], class_=re.compile(r'tag|label|category', re.I))
            print(f"æ‰¾åˆ° {len(tag_elements)} ä¸ªå¯èƒ½çš„æ ‡ç­¾å…ƒç´ ")
            
            for elem in tag_elements[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"  {elem.name}: {elem.get('class')} - {elem.text.strip()}")
                
    except Exception as e:
        print(f"âŒ æ–¹æ³•4å¼‚å¸¸: {e}")

def analyze_colorhunt_structure():
    """åˆ†æColorHuntç½‘ç«™çš„æ•´ä½“ç»“æ„"""
    print("\n" + "=" * 60)
    print("ğŸ—ï¸ åˆ†æColorHuntç½‘ç«™ç»“æ„")
    print("=" * 60)
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
    }
    
    # åˆ†æä¸åŒé¡µé¢çš„ç»“æ„
    pages_to_analyze = [
        ('ä¸»é¡µ', 'https://colorhunt.co/'),
        ('Popularé¡µé¢', 'https://colorhunt.co/popular'),
        ('Vintageæ ‡ç­¾é¡µ', 'https://colorhunt.co/palettes/vintage'),
        ('Natureæ ‡ç­¾é¡µ', 'https://colorhunt.co/palettes/nature')
    ]
    
    for page_name, url in pages_to_analyze:
        print(f"\nğŸ“„ åˆ†æ {page_name}: {url}")
        try:
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # æŸ¥æ‰¾é…è‰²æ–¹æ¡ˆé“¾æ¥
                palette_links = soup.find_all('a', href=re.compile(r'/palette/[a-fA-F0-9]{24}'))
                print(f"  æ‰¾åˆ° {len(palette_links)} ä¸ªé…è‰²æ–¹æ¡ˆé“¾æ¥")
                
                # æŸ¥æ‰¾æ ‡ç­¾é“¾æ¥
                tag_links = soup.find_all('a', href=re.compile(r'/palettes/[a-zA-Z]+'))
                tag_names = [link.text.strip() for link in tag_links if link.text.strip()]
                print(f"  æ‰¾åˆ°æ ‡ç­¾: {list(set(tag_names))}")
                
            else:
                print(f"  âŒ çŠ¶æ€ç : {response.status_code}")
                
        except Exception as e:
            print(f"  âŒ å¼‚å¸¸: {e}")

def test_alternative_approach():
    """æµ‹è¯•æ›¿ä»£æ–¹æ³•ï¼šé€šè¿‡æ ‡ç­¾é¡µé¢åå‘æŸ¥æ‰¾"""
    print("\n" + "=" * 60)
    print("ğŸ”„ æµ‹è¯•æ›¿ä»£æ–¹æ³•ï¼šé€šè¿‡æ ‡ç­¾é¡µé¢åå‘æŸ¥æ‰¾")
    print("=" * 60)
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
    }
    
    target_code = '626f47a4b465f5ecd5f0bb78'
    expected_tags = ['sage', 'green', 'beige', 'nature', 'earth', 'summer', 'food', 'vintage']
    
    found_in_tags = []
    
    for tag in expected_tags:
        print(f"\nğŸ” åœ¨æ ‡ç­¾é¡µé¢ '{tag}' ä¸­æŸ¥æ‰¾é…è‰²æ–¹æ¡ˆ {target_code}")
        try:
            url = f'https://colorhunt.co/palettes/{tag}'
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                if target_code in response.text:
                    found_in_tags.append(tag)
                    print(f"  âœ… åœ¨ {tag} æ ‡ç­¾é¡µé¢ä¸­æ‰¾åˆ°è¯¥é…è‰²æ–¹æ¡ˆ")
                else:
                    print(f"  âŒ åœ¨ {tag} æ ‡ç­¾é¡µé¢ä¸­æœªæ‰¾åˆ°è¯¥é…è‰²æ–¹æ¡ˆ")
            else:
                print(f"  âš ï¸ æ ‡ç­¾é¡µé¢ {tag} è®¿é—®å¤±è´¥: {response.status_code}")
                
        except Exception as e:
            print(f"  âŒ å¼‚å¸¸: {e}")
        
        time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
    
    print(f"\nğŸ“Š ç»“æœæ€»ç»“:")
    print(f"æœŸæœ›æ ‡ç­¾: {expected_tags}")
    print(f"å®é™…æ‰¾åˆ°çš„æ ‡ç­¾: {found_in_tags}")
    print(f"åŒ¹é…ç‡: {len(found_in_tags)}/{len(expected_tags)} = {len(found_in_tags)/len(expected_tags)*100:.1f}%")

def main():
    """ä¸»å‡½æ•°"""
    print("ColorHuntç‰¹å®šé…è‰²æ–¹æ¡ˆæ ‡ç­¾è·å–æµ‹è¯•")
    print("=" * 60)
    
    try:
        test_specific_palette_tags()
        analyze_colorhunt_structure()
        test_alternative_approach()
        
        print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
        print("ğŸ’¡ è¯´æ˜: é€šè¿‡å¤šç§æ–¹æ³•å°è¯•è·å–çœŸå®çš„æ ‡ç­¾ä¿¡æ¯")
        print("ğŸ” æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶æŸ¥çœ‹è¯¦ç»†åˆ†æç»“æœã€‚")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 